---
title: How to effectively write quality code with AI
author: i5heu
created_at: 2026-02-06T18:49:59.000Z
url: https://heidenstedt.org/posts/2026/how-to-effectively-write-quality-code-
with-ai/
points: 42
hn_url: https://news.ycombinator.com/item?id=46916586
comments: 5
---

# How to effectively write quality code with AI

1 Establish a Clear Vision

You are a human, you know how this world behaves, how your team and colleagues
behave, and what your users expect. You have experienced the world, and you want
to work together with a system that has no experience in this world you live in.
Every decision in your project that you don’t take and document will be taken
for you by the AI.

Your responsibility of delivering quality code cannot be met if not even you
know where long-lasting and difficult-to-change decisions are taken.

You must know what parts of your code need to be thought through and what must
be vigorously tested.

Think about and discuss the architecture, interfaces, data structures, and
algorithms you want to use. Think about how to test and validate your code to
these specifications.

2 Maintain Precise documentation

You need to communicate to the AI in detail what you want to achieve, otherwise
it will result in code that is unusable for your purpose.

Other developers also need to communicate this information to the AI. That makes
it efficient to write as much documentation as practical in a standardized
format and into the code repository itself.

Document the requirements, specifications, constraints, and architecture of your
project in detail.

Document your coding standards, best practices, and design patterns.

Use flowcharts, UML diagrams, and other visual aids to communicate complex
structures and workflows.

Write pseudocode for complex algorithms and logic to guide the AI in
understanding your intentions.

3 Build debug systems that aid the AI

Develop efficient debug systems for the AI to use, reducing the need for
multiple expensive CLI commands or browsers to verify code functionality. This
will save time and resources while simplifying the process for the AI to
identify and resolve code issues.

For example: Build a system that collects logs from all nodes in a distributed
system and provides abstracted information like “The Data was send to all
nodes”, “The Data X is saved on Node 1 but not on Node 2”.

4 Mark code review levels

Not all code is equally important. Some parts of your codebase are critical and
need to be reviewed with extra care. Other parts are less important and can be
generated with less oversight.

Use a system that allows you to mark how thoroughly each function has been
reviewed.

For example you can use a prompt that will let the AI put the comment //A

behind functions it wrote to indicate that the function has been written by an
AI and is not yet reviewed by a human.

5 Write high level specifications and test by yourself

AIs will cheat and use shortcuts eventually. They will write mocks, stubs, and
hard coded values to make the code tests succeed while the code itself is not
working and most of the time dangerous. Often AIs will adapt or outright delete
test code to let the code pass tests.

You must discourage this behavior by writing property based high level
specification tests yourself. Build them in a way that makes it hard for the AI
to cheat without having big code segments dedicated to it.

For example, use property based testing, restart the server and check in between
if the database has the correct values.

Separate these test so the AI cannot edit them and prompt the AI not to change
them.

6 Write interface tests in a separate context

Let an AI write property based interface tests for the expected behavior with as
little context of the rest of the code as possible.

This will generate tests that are uninfluenced by the “implementation AI” which
will prevent the tests from being adapted to the implementation in a way that
makes them useless or less effective.

Separate these tests so the AI cannot edit them without approval and prompt the
AI not to change them.

7 Use strict linting and formatting rules

Use strict linting and formatting rules to ensure code quality and consistency.
This will help you and your AI to find issues early.

8 Use context specific coding agent prompts

Save time and money by utilizing path specific coding agent prompts like
CLAUDE.md.

You can generate them automatically which will give your AI information it would
otherwise as to create from scratch every time.

Try to provide as much high level information as practical, such as coding
standards, best practices, design patterns, and specific requirements for the
project. This will help the AI to generate code that is more aligned with your
expectations and will reduce lookup time and cost.

9 Find and mark functions that have a high security risk

Identify and mark functions that have a high security risk, such as
authentication, authorization, and data handling. These functions should be
reviewed and tested with extra care and in such a way that a human has
comprehended the logic of the function in all its dimensions and is confident
about its correctness and safety.

Make this explicit with a comment like //HIGH-RISK-UNREVIEWED

and //HIGH-RISK-REVIEWED

to make sure that other developers are aware of the importance of these
functions and will review them with extra care.

Make sure that the AI is instructed to change the review state of these
functions as soon as it changes a single character in the function.

Developers must make sure that the status of these functions is always correct.

10 Reduce code complexity where possible

Aim to reduce the complexity of the generated code where possible. Each single
line of code will eat up your context window and make it harder for the AI and
You to keep track of the overall logic of your code.

Each avoidable line of code is costing energy, money and probability of future
unsuccessful AI tasks.

11 Explore problems with experiments and prototypes

AI written code is cheap, use this to your advantage by exploring different
solutions to a problem with experiments and prototypes with minimal
specifications. This will allow you to find the best solution to a problem
without investing too much time and resources in a single solution.

12 Do not generate blindly or to much complexity at once

Break down complex tasks into smaller, manageable tasks for the AI. Instead of
asking the AI to generate the complete project or component at once, break it
down into smaller tasks, such as generating individual functions or classes.
This will help you to maintain control over the code and it’s logic.

You have to check each component or module for its adherence to the
specifications and requirements.

If you have lost the overview of the complexity and inner workings of the code,
you have lost control over your code and must restart from a state where you
were in control of your code.

--------------------------------------------------------------------------------
## Comments

OptionOfT: I wonder at the end of this if it's the still worth the risk?  A lot
of how I form my thoughts is driven by writing code, and seeing it on screen,
running into its limitations.  Maybe it's the kind of work I'm doing, or maybe I
just suck, but the code to me is a forcing mechanism into ironing out the
details, and I don't get that when I'm writing a specification.

    discreteevent: Exactly. 30 years ago a mathematician I knew said to me: "The one
    thing that you can say for programming is that it forces you to be precise."  We
    vibe around a lot in our heads and that's great. But it's really refreshing,
    every so often, to be where the rubber meets the road.

    shinryuu: I couldn't agree more. It's often when you are in the depth of the
    details that I make important decisions on how to engineer the continuation.

        jofla_net: Yes, I look at this in a similar vein to the (Eval <--> Appply) Cycle
        in SICP textbook, as a (Design <--> Implement) cycle.

    tayo42: I was just thinking this the other day after I did a coding screen and
    didn't do well. I know the script for the interviewee is your not suppsed to
    write any code until you talk through the whole thing, but I think i woukd have
    done better if I could have just wrote a bunch of throw away code to iterate on.

    jeppester: That's also how I feel.  I think you have every right to doubt those
    telling us that they run 5 agents to generate a new SAAS-product while they are
    sipping latté in a bar. To work like that I believe you'll have to let go of
    really digging into the code, which in my experience is needed if want good
    quality.  Yet I think coding agents can be quite a useful help for some of the
    trivial, but time consuming chores.  For instance I find them quite good at
    writing tests. I still have to tweak the tests and make sure that they do as
    they say, but overall the process is faster IMO.  They are also quite good at
    brute-forcing some issue with a certain configuration in a dark corner of your
    android manifest. Just know that they WILL find a solution even if there is
    none, so keep them on a leash!  Today I used Claude for bringing a project I
    abandoned 5 years ago up to speed. It's still at work in progress, but the task
    seemed insurmountable (in my limited spare time) without AI, now it feels like
    I'm half-way there in 2-3 hours.

    agumonkey: I second this. This* is the matter against which we form
    understanding. This here is the work at hand, our own notes, discussions we have
    with people, the silent walk where our brain kinda process errors and ideas ..
    it's always been like this since i was a kid, playing with construction toys. I
    never ever wanted somebody to play while I wait to evaluate if it fits my
    desires. Desires that often come from playing.  Outsourcing this to an LLM is
    similar to an airplane stall .. I just dip mentally. The stress goes away too,
    since I assume the LLM will get rid of the "problem" but I have no more
    incentives to think, create, solve anything.  Still blows my mind how different
    people approach some fields. I see people at work who are drooling about being
    able to have code made for them .. but I'm not in that group.

        Akranazon: Everything you have said here is completely true, except for "not in
        that group": the cost-benefit analysis clearly favors letting these tools rip,
        even despite the drawbacks.

            agumonkey: Oh I'm well aware of this. I admitted defeat in a way.. I can't
            compete. I'm just at loss, and unless LLM stall and break for some reason (ai
            bubble, enshittification..) I don't see a future for me in "software" in a few
            years.

    vunderba: Sounds like the coders equivalent of the Whorfian hypothesis.

    PeterStuer: Any sufficiently detailed specification converges on code.

    chasd00: Using AI or writing your own code isn't an xor thing. You can still
    write the code but have a coding assistant or something an alt/cmd-tab away. I
    enjoy writing code, it relaxes me so that's what I do but when I need to look
    something up or i'm not clear on the syntax for some particular operation
    instead of tabbing to a browser and google.com I tab to the agent and ask it to
    take a look. For me, this is especially helpful for CSS and UI because I really
    suck at and dislike that part of development.  I also use these things to just
    plan out an approach. You can use plan mode for yourself to get an idea of the
    steps required and then ask the agent to write it to a file. Pull up the file
    and then go do it yourself.

    wasmainiac: I also second this. I find that I write better by hand, although I
    work on niche applications it’s not really standard crud or react apps. I use
    LLMs in the same way i used to used stack overflow, if I go much farther to
    automate my work than that I spend more time on cleanup compared to if I just
    write code myself.  Sometimes the AI does weird stuff too. I wrote a texture
    projection for a nonstandard geometric primitive, the projection used some math
    that was valid only for local regions… long story. Claude kept on wanting to
    rewrite the function to what it thought was correct (it was not) even when I
    directed to non related tasks. Super annoying. I ended up wrapping the function
    in comments telling it to f#=% off before I would leave it alone.

einpoklum: That sounds like the advice of someone who doesn't actually write
high-quality code. Perhaps a better title would be "how to get something better
than pure slop when letting a chatbot code for you" - and then it's not bad
advice I suppose. I would still avoid such code if I can help it at all.

    Akranazon: Man, you are really missing out of the biggest revolution of my life.
    This is the opinion of someone who has not tried to use Claude Code, in a brand
    new project with full permissions enabled, and with a model from the last 3
    months.

        whynotminot: This is a fading but common sentiment on hacker news.  There’s a
        lot of engineers who will refuse to wake up to the revolution happening in front
        of them.  I get it. The denialism is a deeply human response.

    computerex: Can you be specific? You didn't provide any constructive feedback,
    whatsoever.

egrtah: Too bad that software developers are carrying water for those who hate
them and mock them for being obsolete in 6-12 months, while they are eating
caviar (probably evading sanctions) and clink the champagne glasses in Davos:
https://xcancel.com/hamptonism/status/2019434933178306971  And all that after
stealing everyone's output.

whynotminot: The real value that AI provides is the speed at which it works, and
its almost human-like ability to “get it” and reasonably handle ambiguity.
Almost like tasking a fellow engineer. That’s the value.  By the time you do
everything outlined here you’ve basically recreated waterfall and lost all speed
advantage. Might as well write the code yourself and just use AI as first-pass
peer review on the code you’ve written.  A lot of the things the writer points
out also feel like safeguards against the pitfalls of older models.  I do agree
with their 12th point. The smaller your task the easier to verify that the model
hasn’t lost the plot. It’s better to go fast with smaller updates that can be
validated, and the combination of those small updates gives you your final
result. That is still agile without going full “specifications document”
waterfall.

raphman: Hi i5heu. Given that you seem to use AI tools for generating images and
audio versions of your posts, I hope it is not too rude to ask: how much of the
post was drafted, written or edited with AI?  The suggestions you make are all
sensible but maybe a little bit generic and obvious. Asking ChatGPT to generate
advice on effectively writing quality code with AI generates a lot of similar
suggestions (albeit less well written).  If this was written with help of AI,
I'd personally appreciate a small notice above the blog post. If not, I'd
suggest to augment the post with practical  examples or anecdotal experience. At
the moment, the target group seems to be  novice programmers rather than the
typical HN reader.